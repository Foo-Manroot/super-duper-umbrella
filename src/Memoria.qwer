	En este documento se explica la estructura de la práctica y se adjuntan todas las cabeceras de las carpetas (donde se declaran y documentan las funciones utilizadas).

	Para implementar cada una de las partes, se han creado distintas carpetas con todos los archivos fuente y cabeceras necesarias:
		-> Para la implementación sólo con CPU, la carpeta cpu/
		-> Para la implementación con GPU (CUDA), la carpeta cuda/
		-> Para GPU (CUDA) con optimizaciones, la carpeta optimizada/
		-> Para la parte final, con OpenGL, la carpeta openGL/

	Para compilar cada una de las carpetas, se pueden usar los Makefile (sólo hace falta ejecutar `make`) para crear el ejecutable 'candy'. Para ver las opciones admitidas, se puede usar `./candy -h`. La salida es la siguiente (en todas las implementaciones es la misma):
>
>		Práctica de Ampliación de Programación Avanzada.
>		Daniel Estangüi y Miguel García
>	Uso correcto:
>	./candy [-hman:f:c:v]
>		-h
>			Muestra este mensaje de ayuda y sale del programa
>		-a | -m
>			Habilita la ejecución automática (-a) o manual (-m). Si no se especifica, se habilita la ejecución automática por defecto. Estas opciones son excluyentes
>		-n <nivel>
>			Si se especifica, establece el nivel de inicio (del 1 al 3)
>		-f <nº_filas>
>			Establece el número de filas de la matriz de juego
>		-c <nº_columnas>
>			Establece el número de columnas de la matriz de juego
>		-v
>			Incrementa el nivel de detalle
>

	Como se puede ver, '-v' permite aumentar el nivel de detalle, lo que aumenta el número de mensajes que se muestran. Hay tres niveles: LOG (sin -v), DEBUG (-v) y EXTRA (-vv).


	Se puede usar el Makefile global (el que está en src/) para compilar todo ejecutando `make`. Si se ejecuta, por ejemplo, `make cuda` se compila, ejecuta el programa de cuda/, tras lo que se limipian automáticamente todos los archivos generados. Lo mismo es aplicable al resto de implementaciones.


	Las optimizaciones realizadas son las siguientes (este es el mismo contenido que optimizada/optimizaciones.asdf):

	En gen_aleat gen_aleat_cuda() no tiene sentido usar memoria compartida, pues
sólo se accede a la matriz una vez (para escribir el valor generado).

	En realidad no se optimiza nada usando memoria compartida, dado que los núcleos
o bien no realizan suficientes lecturas o escrituras como para que compense el uso de
memoria compartida, o directamente no usan la memoria global más que para escribir el
resultado (como en gen_aleat_cuda). Sin embargo, somo se pide en la práctica, se ha
implementado en los siguientes núcleos:
	-> eliminar_fila_cuda
	-> eliminar_columna_cuda
	-> girar_matriz_cuda
	-> buscar_coinc_cuda_fila (aquí se usan dos matrices en memoria compartida)
	-> buscar_coinc_cuda_col (se usan dos matrices en memoria compartida)
	-> llenar_vacios_cuda (es el único núcleo en el que se disminuye realmente el
		número de accesos a memoria global)


	El único sitio donde sí puede llevar alguna ventaja el uso de memoria
compartida, debido al gran número de accesos, es buscar_lleno()


	Además, se ha usado el desenrrollamiento en el bucle para copiar el cuadrante de
3x3 en la memoria compartida, dentro del núcleo 'girar_matriz_cuda'
